## 概述
本文档分为三个部分 ：CAS操作，C++内存序详解，和C++原子操作的实现原理


## 一. CAS操作

### 1. CAS概念

CAS（Compare-And-Swap）比较-交换操作（可以记成读改写操作）是现代处理器提供的一种原子操作，它是无锁编程的基础。CAS操作的核心思想是"乐观锁"：假设没有冲突，直接尝试修改，如果发现冲突则重试。

CAS操作的本质行为：原子性地比较内存值与期望值是否相等，如果相等则更新为新值，否则不做任何操作。
### 2.2 C++中的CAS接口详解

C++提供了两个CAS接口：`compare_exchange_weak`和`compare_exchange_strong`。

#### 1.2.1 compare_exchange_weak详解

**函数签名：**
```cpp
bool compare_exchange_weak(T& expected, T desired, 
                          std::memory_order success = std::memory_order_seq_cst,
                          std::memory_order failure = std::memory_order_seq_cst);
```

**参数说明**：
- expected ：期望的当前值，如果CAS失败，会被更新为实际的当前值
- desired ：要设置的新值
- success ：CAS成功时的内存序
- failure ：CAS失败时的内存序

**关键特性：**
1. **可能虚假失败**：即使当前值等于期望值，也可能返回false
2. **性能优化**：在某些架构上避免了额外的循环
3. **适合循环使用**：通常与while循环配合

**虚假失败的原因：**
- **LL/SC架构**：某些处理器（如ARM）使用Load-Linked/Store-Conditional指令
- **中断干扰**：操作过程中发生中断可能导致失败
- **缓存行竞争**：高竞争环境下的缓存行争用

**接口使用：**
```cpp
std::atomic<int> counter{0};

void atomic_increment() {
    int current = counter.load();
    
    // 标准的weak CAS循环模式
    while (!counter.compare_exchange_weak(current, current + 1)) {
        // current会被自动更新为实际的当前值
        // 继续尝试直到成功
    }
}

// 更复杂的例子：原子地将值设置为最大值
void atomic_max(std::atomic<int>& target, int value) {
    int current = target.load();
    
    while (current < value && 
           !target.compare_exchange_weak(current, value)) {
        // 如果current >= value，循环自动退出
        // 如果CAS失败，current被更新，继续尝试
    }
}
```

**内存序的使用：**
```cpp
void optimized_increment() {
    int current = counter.load(std::memory_order_relaxed);
    
    while (!counter.compare_exchange_weak(
        current, current + 1,
        std::memory_order_relaxed,  // 成功时的内存序
        std::memory_order_relaxed   // 失败时的内存序
    )) {
        // 使用relaxed内存序提高性能
    }
}
```

#### 1.2.2 compare_exchange_strong详解

**函数签名：**
```cpp
bool compare_exchange_strong(T& expected, T desired,
                           std::memory_order success = std::memory_order_seq_cst,
                           std::memory_order failure = std::memory_order_seq_cst);
```

**参数说明**：
- expected ：期望的当前值，如果CAS失败，会被更新为实际的当前值
- desired ：要设置的新值
- success ：CAS成功时的内存序
- failure ：CAS失败时的内存序

**关键特性：**
1. **不会虚假失败**：只有在值真的不匹配时才返回false
2. **适合单次尝试**：不需要循环的场景
3. **可能有额外开销**：在某些架构上需要内部循环

**典型使用场景：**
```cpp
std::atomic<bool> lock_flag{false};

// 尝试获取锁（单次尝试）
bool try_lock() {
    bool expected = false;
    return lock_flag.compare_exchange_strong(expected, true);
    // 如果返回true，成功获得锁
    // 如果返回false，锁已被其他线程持有
}

// 释放锁
void unlock() {
    lock_flag.store(false);
}

// 使用示例
void worker() {
    if (try_lock()) {
        // 获得锁，执行临界区代码
        critical_section();
        unlock();
    } else {
        // 未获得锁，执行其他工作
        do_other_work();
    }
}
```


### 1.3 两个CAS接口的选择

#### 性能对比

| 场景    | compare_exchange_weak | compare_exchange_strong |
| ----- | --------------------- | ----------------------- |
| 循环中使用 | ✅ 推荐                  | ❌ 可能有额外开销               |
| 单次尝试  | ❌ 可能虚假失败              | ✅ 推荐                    |
| 高竞争环境 | ✅ 更好的性能               | ❌ 可能性能较差                |
| 低竞争环境 | ✅ 性能相当                | ✅ 性能相当                  |

#### 实际代码模式对比

**使用weak的正确模式：**
```cpp
// ✅ 正确：weak配合循环
void increment_weak() {
    int current = counter.load();
    while (!counter.compare_exchange_weak(current, current + 1)) {
        // 自动重试
    }
}

// ❌ 错误：weak不配合循环
void increment_wrong() {
    int current = counter.load();
    if (!counter.compare_exchange_weak(current, current + 1)) {
        // 可能因为虚假失败而错过更新机会
    }
}
```

**使用strong的正确模式：**
```cpp
// ✅ 正确：strong用于单次尝试
bool try_increment_once() {
    int current = counter.load();
    return counter.compare_exchange_strong(current, current + 1);
}

// ✅ 也可以：strong配合循环（但可能性能较差）
void increment_strong() {
    int current = counter.load();
    while (!counter.compare_exchange_strong(current, current + 1)) {
        // 重试，但可能有额外开销
    }
}
```



## 二. C++五种内存序详解
### memory_order_relaxed (松散内存序)

#### 内存序特点
- 只保证单个原子变量操作的原子性
- 不提供任何跨变量的顺序保证
- 允许编译器和CPU自由重排指令
- 性能开销最小
- 适用于简单计数器等场景

#### 代码示例
```cpp
#include <atomic>
#include <cassert>
#include <iostream>
#include <thread>

std::atomic<int> x{0}, y{0};
std::atomic<int> count{0};

void write_x_then_y() {
    x.store(1, std::memory_order_relaxed);  // 操作1
    y.store(1, std::memory_order_relaxed);  // 操作2
}

void read_y_then_x() {
    while (y.load(std::memory_order_relaxed) == 0);  // 操作3：等待y变为1
    if (x.load(std::memory_order_relaxed) == 0) {    // 操作4
        count++;                                     // 如果x还是0，计数器加1
    }
}

void test_demo() {
    std::thread t1(write_x_then_y);
    std::thread t2(read_y_then_x);
    t1.join();
    t2.join();
}

int main() {
    test_demo();
    std::cout << count << std::endl;
    return 0;
}
```

#### 代码分析
1. **线程1执行流程**：
   - 先给x赋值1
   - 再给y赋值1
   - 从代码看起来x应该在y之前被设置

2. **线程2执行流程**：
   - 等待y变成1
   - 一旦y变成1，立即检查x的值
   - 如果x还是0，就让count加1

3. **问题出现**：
   - 由于使用relaxed内存序，CPU可能会重排线程1中的指令
   - 实际执行时可能先设置y=1，再设置x=1
   - 这样线程2就会看到y=1但x=0的情况

4. **结果**：
   - count可能不为0，但是由于cpu架构和指令集差异和现代编译器优化，这种情况非常难复现。
   - 这证明了relaxed内存序允许指令重排

### memory_order_seq_cst (顺序一致性内存序)

#### 内存序特点
- 最强的内存序约束
- 保证全局统一的操作顺序
- 所有线程观察到相同的操作序列
- 性能开销最大
- C++原子操作的默认内存序

#### 代码示例
```cpp
#include <atomic>
#include <cassert>
#include <iostream>
#include <thread>

std::atomic<int> x{0}, y{0};
std::atomic<int> count{0};

void write_x_then_y() {
    x.store(1, std::memory_order_seq_cst);  // 操作1
    y.store(1, std::memory_order_seq_cst);  // 操作2
}

void read_y_then_x() {
    while (y.load(std::memory_order_seq_cst) == 0);  // 操作3：等待y变为1
    if (x.load(std::memory_order_seq_cst) == 0) {    // 操作4
        count++;                                     // 如果x还是0，计数器加1
    }
}

void test_demo() {
    std::thread t1(write_x_then_y);
    std::thread t2(read_y_then_x);
    t1.join();
    t2.join();
}

int main() {
    test_demo();
    std::cout << count << std::endl;
    return 0;
}
```

#### #### 代码分析
1. **线程1执行流程**：
   - 先给x赋值1
   - 再给y赋值1
   - 从代码看起来x应该在y之前被设置

2. **线程2执行流程**：
   - 等待y变成1
   - 一旦y变成1，立即检查x的值
   - 如果x还是0，就让count加1

3. **问题出现**：
   - 由于使用seq_cst内存序,限制了所有内存指令的重排序
   - 实际执行时只能先设置x=1，再设置y=1

4. **结果**：
   - count一定为0，
### memory_order_release (发布内存序)

#### 内存序特点
- 用于store操作
- 防止之前的读写操作被重排到release操作之后
- 与acquire操作配对使用
- 发布之前所有内存修改的可见性
- 是同步机制的"发送端"
### memory_order_acquire (获取内存序)

#### 内存序特点
- 用于load操作
- 防止后续的读写操作被重排到acquire操作之前
- 与release操作配对使用
- 能够"看到"配对release操作之前的所有写入
- 性能介于relaxed和seq_cst之间

#### 代码示例
```cpp
#include <atomic>
#include <cassert>
#include <iostream>
#include <thread>

std::atomic<bool> ready;
std::atomic<int>  data;

void produce() {
    data.store(100, std::memory_order_relaxed);
    ready.store(true, std::memory_order_release);
    std::cout << " produce data:" << data << std::endl;
}
void cousume() {
    while (!ready.load(std::memory_order_acquire));
    std::cout << " consume data:" << data << std::endl;
}

void test_demo() {
    ready = false;
    data = 0;
    std::thread producer(produce);
    std::thread consumer(cousume);
    producer.join();
    consumer.join();
}

int main() {
    test_demo();
    return 0;
}
```

#### 代码分析
**1.生产者线程 **：
- 先写入数据100到 data 变量，因为使用了 memory_order_relaxed 内存序，所以只保证写入的原子性，不提供同步约束

- 再设置 ready 为true，因为使用了 memory_order_release 内存序，所以确保之前所有内存操作（包括写入data）在此操作前完成并对其他线程可见

**2.消费者线程** ：
- 循环检查 ready 是否为true，因为使用了 memory_order_acquire 内存序，所以一旦读取到true，就能保证看到生产者在release操作之前的所有写入

- 读取并输出 data 的值，因为acquire-release语义的配对使用，所以能确保读取到生产者写入的正确数据100


### memory_order_acq_rel (获取-发布内存序)

#### 内存序特点
- 结合acquire和release语义
- 用于读-修改-写操作
- 既能"看到"之前的写入，又能"发布"当前的修改
- 适用于compare_exchange等原子操作
- 能建立链式同步关系

#### 代码示例
```cpp
#include <atomic>
#include <thread>
#include <iostream>
#include <cassert>
#include <chrono>

std::atomic<int> sync_flag{0};
int shared_data = 0;

void thread1() {
    std::cout << "线程1：开始工作" << std::endl;
    
    // 修改共享数据
    shared_data = 100;
    std::cout << "线程1：设置shared_data = " << shared_data << std::endl;
    
    // 发布第一阶段完成信号
    sync_flag.store(1, std::memory_order_release);
    std::cout << "线程1：发布完成信号(sync_flag = 1)" << std::endl;
}

void thread2() {
    std::cout << "线程2：等待线程1完成..." << std::endl;
    
    int expected = 1;
    // 使用acq_rel尝试将flag从1改为2
    while (!sync_flag.compare_exchange_weak(expected, 2, std::memory_order_acq_rel)) {
        expected = 1;  // 重置期望值
        std::this_thread::sleep_for(std::chrono::milliseconds(1));
    }
    
    std::cout << "线程2：成功获取控制权，sync_flag从1改为2" << std::endl;
    std::cout << "线程2：读取到shared_data = " << shared_data << std::endl;
    
    // 现在可以安全访问shared_data（能看到线程1的修改）
    assert(shared_data == 100);
    
    // 进行自己的修改
    shared_data += 50;
    std::cout << "线程2：修改shared_data = " << shared_data << std::endl;
    
    // acq_rel的release部分会确保这个修改对后续线程可见
}

void thread3() {
    std::cout << "线程3：等待线程2完成..." << std::endl;
    
    // 等待线程2完成
    while (sync_flag.load(std::memory_order_acquire) != 2) {
        std::this_thread::sleep_for(std::chrono::milliseconds(1));
    }
    
    std::cout << "线程3：检测到sync_flag = 2，开始工作" << std::endl;
    std::cout << "线程3：读取到shared_data = " << shared_data << std::endl;
    
    // 现在可以看到线程1和线程2的所有修改
    assert(shared_data == 150);
    std::cout << "线程3：数据验证通过" << std::endl;
}

int main() {
    std::thread t1(thread1);
    std::thread t2(thread2);
    std::thread t3(thread3);
    
    t1.join();
    t2.join();
    t3.join();
    
    std::cout << "程序执行完成，最终shared_data = " << shared_data << std::endl;
    return 0;
}
```

#### 代码分析
1. **线程1的工作**：
   - 设置shared_data为100
   - 用release方式设置sync_flag为1，表示"第一阶段完成"

2. **线程2的工作**：
   - 尝试将sync_flag从1改为2
   - 使用acq_rel内存序，这意味着：
     - acquire部分：能看到线程1设置的shared_data=100
     - release部分：将自己的修改shared_data+=50发布出去

3. **compare_exchange的原子性**：
   - 要么看到期望值1并成功改为2
   - 要么看到其他值并失败
   - 不会出现中间状态

4. **线程3的等待**：
   - 等待sync_flag变成2
   - 一旦看到2，就知道前面两个线程的工作都完成了
   - 此时shared_data的值必然是150

5. **链式传递**：
   - 线程1→线程2→线程3形成了一条同步链
   - 每个环节都能看到前面所有的修改


### 总结
- 绝大多数情况下只需要acq、rel和relaxed的内存序
- releaxed的内存用于对该变量读写值不关心的情况，比如读写顺序彻底乱排也不影响程序逻辑，变量之间相互独立且无同步关系，比如只是用来计数统计结果
- seq_cst内存序的使用场景为，当存在多个线程和多个原子变量，并且程序逻辑强依赖于多个原子变量的读写时，需要全局存在一个原子变量读写顺序时，才使用该内存序。
- 其他情况都用acq或rel或两者结合的内存序即可。
- 实际操作中可以在最初写代码的时候统一全部使用seq_cst，然后确保代码逻辑和功能没问题之后逐步放宽内存序。



## 三. C++原子操作原理分析

##### 回顾：内存序的核心作用

内存序解决两个关键问题：

1. **防止指令重排序** - 在关键点设置"屏障"，确保重要操作按预期顺序执行
2. **控制内存可见性** - 确保一个线程的修改能被其他线程在正确的时机看到

### 原子操作原理的核心要点
1. **缓存锁定技术** - 实现原子操作的直接原理
2. **总线锁定机制** - 特殊情况下实现原子操作的方式
3. **CPU多级缓存架构** - 内存可见性问题的根本原因
4. **MESI缓存一致性协议** - 保证多核间缓存数据一致性的机制（内存可见性的规则）
5. **硬件内存屏障机制** - C++内存序实现限制指令重排的原理

#####  缓存行的概念

- **基本单位**：以64字节为单位的缓存数据管理,cpu访问数据的最小单位
- **通俗理解**：CPU在访问缓存数据的时候不是一个字节一个字节地搬运数据，而是一次搬运64字节的"数据块"
- **影响**：相邻的变量可能在同一个缓存行中，修改一个会影响整行的状态
- **对齐优化**：将频繁访问的原子变量对齐到缓存行边界，避免伪共享问题

### 1. 缓存锁定技术

- **主要方式**：锁定特定缓存行实现原子操作
- **工作原理**：当执行原子操作时，CPU会锁定包含目标数据的缓存行，防止其他核心同时修改
- **实现机制**：通过LOCK前缀指令实现，确保RMW（读-修改-写）操作的原子性
- **通俗理解**：就像在修改文件时给文件加锁，确保同一时间只有一个人能修改
- **优势**：比总线锁定更高效，只影响特定的缓存行

### 2. 总线锁定机制

- **备选方案**：特殊情况下锁定整个内存总线
- **使用场景**：
  - 数据跨越多个缓存行
  - 操作的数据不在缓存中
  - 某些老旧的CPU架构
- **通俗理解**：就像封锁整条道路来确保安全，虽然有效但影响范围大
- **缺点**：性能开销较大，会阻塞其他所有内存访问
- **现代趋势**：现代CPU尽量避免使用总线锁定
### 3. CPU多级缓存架构

现代cpu引入了多级缓存架构

![本地图片](CPU多级缓存结构图.png)
#### 3.1 CPU访问数据的位置
CPU访问数据时，数据不是只从内存中读取。
#### 3.2CPU访问数据的顺序
当CPU需要访问数据时，遵循以下查找顺序：
1. **寄存器查找** - 检查CPU寄存器中是否有所需数据
2. **L1缓存命中** - 直接从L1缓存读取（1-2个时钟周期）
3. **L1缓存未命中，L2缓存命中** - 从L2缓存读取并更新L1（10-20个时钟周期）
4. **L2缓存未命中，L3缓存命中** - 从L3缓存读取并更新L2、L1（40-75个时钟周期）
5. **L3缓存未命中** - 从主内存读取并更新各级缓存（200-300个时钟周期）



### 4. MESI缓存一致性协议详解

#### 4.1 四种状态概述

MESI协议通过四种状态来管理多核CPU之间的缓存一致性：

- **M (Modified)** - 已修改状态
- **E (Exclusive)** - 独占状态  
- **S (Shared)** - 共享状态
- **I (Invalid)** - 无效状态

#### 4.2 四种状态详解

**M (Modified) - 已修改状态**：
- **含义**：缓存行数据已被修改，与主内存不一致
- **特点**：只有当前核心拥有最新数据，其他核心的副本都无效
- **责任**：必须在被替换前写回主内存
- **权限**：可以直接读写，无需总线通信

**E (Exclusive) - 独占状态**：
- **含义**：缓存行数据与主内存一致，且只在当前核心存在
- **特点**：数据干净且独占，可以直接修改而无需通知其他核心
- **优势**：从E状态转换到M状态无需总线通信
- **权限**：可以直接读写

**S (Shared) - 共享状态**：
- **含义**：多个核心都有相同的干净数据副本
- **特点**：数据与主内存一致，但要修改需要先获取独占权
- **限制**：修改前必须通知其他核心使其副本无效
- **权限**：只能读取，写入需要先获取独占权

**I (Invalid) - 无效状态**：
- **含义**：缓存行数据已过期或不存在
- **特点**：访问时必须从其他核心或主内存重新获取
- **触发**：其他核心修改了共享数据时会收到无效化消息
- **权限**：无法读写，需要重新获取数据

#### 4.3 通俗解释

MESI协议就像图书馆的图书管理系统：

- **M状态**：你借了一本书并在上面做了笔记，这本书只有你有，而且内容已经改变
- **E状态**：你独自拥有一本干净的书，想在上面做笔记可以直接写
- **S状态**：多个人都有同一本书的复印件，如果要修改必须先通知其他人
- **I状态**：你的书已经过期了，要用的话必须重新去图书馆借

#### 4.4 具体工作示例

**示例代码**：
```cpp
#include <atomic>
#include <thread>

std::atomic<int> shared_counter{100};  // 共享原子变量

void thread1_function() {
    // 线程1：读取并修改
    int value = shared_counter.load();     // 步骤1：读取操作
    shared_counter.store(value + 50);      // 步骤3：原子写入操作
}

void thread2_function() {
    // 线程2：读取操作
    int value = shared_counter.load();     // 步骤2和4：读取操作
}
```

**详细执行过程分析**：

**初始状态**：
- Core0缓存：无
- Core1缓存：无  
- 主内存：shared_counter = 100

**步骤1：Core0执行读取操作**
```cpp
int value = shared_counter.load();  // Core0读取
```
- **操作**：Core0首次读取shared_counter
- **MESI状态变化**：
  - Core0缓存：shared_counter=100 [E状态] （独占，因为只有Core0缓存了此数据）
  - Core1缓存：无
  - 主内存：shared_counter=100
- **解释**：由于没有其他核心缓存此数据，Core0获得独占权

**步骤2：Core1也要读取**
```cpp
int value = shared_counter.load();  // Core1读取
```
- **操作**：Core1读取shared_counter
- **MESI协议处理过程**：
  1. Core1发送读取请求到总线
  2. Core0检测到总线上的读取请求，发现自己有该数据
  3. Core0响应请求，提供数据给Core1
  4. 两个核心的状态都变为S（共享）
- **MESI状态变化**：
  - Core0缓存：shared_counter=100 [S状态] （共享）
  - Core1缓存：shared_counter=100 [S状态] （共享）
  - 主内存：shared_counter=100

**步骤3：Core0执行原子写入操作**
```cpp
shared_counter.store(value + 50);  // Core0原子写入
```
- **操作**：Core0执行原子写入操作
- **MESI协议处理过程**：
  1. Core0发送"Read for Ownership"（RFO）请求
  2. Core1收到无效化消息，将缓存行标记为I状态
  3. Core0获得独占权，执行写入操作
  4. Core0缓存行状态变为M（已修改）
- **MESI状态变化**：
  - Core0缓存：shared_counter=150 [M状态] （已修改，独占）
  - Core1缓存：shared_counter=100 [I状态] （无效）
  - 主内存：shared_counter=100 （尚未更新）
- **关键点**：此时Core1的缓存已无效，如果Core1要读取数据，必须重新获取

**步骤4：Core1再次读取**
```cpp
int value = shared_counter.load();  // Core1再次读取
```
- **操作**：Core1读取shared_counter（此时Core1缓存无效）
- **MESI协议处理过程**：
  1. Core1发现自己的缓存行无效，发送读取请求
  2. Core0检测到请求，必须先将修改写回内存（因为Core0处于M状态）
  3. Core0将shared_counter=150写回主内存，自己的状态变为S
  4. Core1从内存读取最新值，状态也为S
- **MESI状态变化**：
  - Core0缓存：shared_counter=150 [S状态] （共享）
  - Core1缓存：shared_counter=150 [S状态] （共享）
  - 主内存：shared_counter=150 （已更新）

**关键观察点**：
- MESI协议确保了数据一致性：Core1最终读到了Core0修改后的值150
- 原子操作配合MESI协议，保证了修改操作的原子性和可见性
- 状态转换过程中的通信开销是多核并发的性能瓶颈之一



### 5. 硬件内存屏障机制原理

#### 5.1 硬件内存屏障的本质

硬件内存屏障是CPU提供的一种**硬件指令**，其核心作用是**控制CPU内部的指令执行流水线和内存子系统**，确保内存操作按照程序员期望的顺序执行。

#### 5.2 CPU乱序执行的硬件原理

**指令流水线重排**：
- 现代CPU采用超标量架构，可以同时执行多条指令
- CPU会分析指令间的依赖关系，将无依赖的指令重新排序执行
- 内存访问指令也会被重排，导致内存操作顺序与程序顺序不一致

**写缓冲区（Store Buffer）**：
- CPU内部有写缓冲区，写操作先进入缓冲区，稍后才写入缓存
- 这导致写操作的可见性延迟
- 不同核心看到写操作的时间可能不同

**无效化队列（Invalidation Queue）**：
- 当收到其他核心的无效化消息时，不会立即处理
- 消息先进入无效化队列，稍后才真正无效化缓存行
- 这导致读操作可能读到已经"应该无效"的旧数据

#### 5.3 内存屏障的硬件实现机制

**流水线暂停机制**：
```
正常流水线：
指令1 → 指令2 → 指令3 → 内存屏障 → 指令4 → 指令5

屏障作用：
指令1 → 指令2 → 指令3 → [等待前面指令完成] → 指令4 → 指令5
```

**写缓冲区刷新**：
- 内存屏障强制CPU将写缓冲区中的所有写操作立即执行
- 确保写操作真正到达缓存，对其他核心可见
- 这是写屏障（Store Barrier）的核心机制

**无效化队列处理**：
- 内存屏障强制CPU立即处理无效化队列中的所有消息
- 确保读操作不会读到已经无效的缓存数据
- 这是读屏障（Load Barrier）的核心机制

**缓存一致性协议同步**：
- 内存屏障与MESI协议配合工作
- 确保缓存状态转换在屏障点完成
- 保证多核间的数据一致性时序



### 这些机制如何协同工作

### 完整的原子操作流程

1. **检测阶段**：CPU检查目标数据所在的缓存行状态（MESI协议）
2. **获取阶段**：根据MESI协议获取缓存行的独占权（可能需要无效化其他核心的副本）
3. **屏障阶段**：根据内存序要求插入相应的硬件内存屏障指令
4. **锁定阶段**：使用缓存锁定或总线锁定保护操作
5. **执行阶段**：在锁定保护下执行读-修改-写操作
6. **同步阶段**：通过内存屏障确保操作的可见性和顺序性
7. **释放阶段**：释放锁定，更新缓存行状态，通知其他核心


### C++强一致内存序（memory_order_seq_cst）过程概述

#### 步骤1：编译器处理
- 识别`memory_order_seq_cst`标记
- 禁止所有指令重排序优化
- 生成最严格的硬件屏障指令（LOCK前缀或MFENCE）

#### 步骤2：CPU流水线控制
- 检测到屏障指令后暂停指令流水线
- 等待所有前序指令完成执行
- 清空指令预取缓冲区和预测执行状态

#### 步骤3：内存子系统同步
- 强制刷新写缓冲区中的所有待写入数据
- 立即处理无效化队列中的所有消息
- 确保所有缓存状态转换完成

#### 步骤4：MESI协议严格执行
- 通过总线发送RFO请求获取缓存行独占权
- 强制其他核心立即无效化相关缓存行
- 等待所有核心确认无效化完成

#### 步骤5：原子操作执行
- 在独占锁定保护下执行读/写/RMW操作
- 操作结果立即同步到共享缓存层（L3）
- 通过缓存一致性协议通知所有核心

#### 步骤6：全内存屏障生效
- 插入硬件全屏障阻止后续操作重排
- 确保当前操作对所有核心立即可见
- 建立全局同步点

#### 步骤7：总线仲裁与全局排序
- 通过总线仲裁机制确定操作的全局执行顺序
- 保证所有线程看到相同的操作序列
- 阻止导致不一致结果的执行顺序

#### 步骤8：释放控制权
- 释放缓存行锁定和总线控制权
- 允许其他核心继续执行内存操作
- 维护全局一致性状态



### C++宽松内存序（memory_order_relaxed）过程概述

#### 步骤1：编译器处理
- 识别`memory_order_relaxed`标记
- 允许大部分指令重排序优化
- 仅生成基本的原子操作指令，不插入内存屏障

#### 步骤2：CPU流水线正常运行
- 不暂停指令流水线
- 允许乱序执行和指令重排
- 保持预取缓冲区和预测执行状态

#### 步骤3：内存子系统异步处理
- 写操作进入写缓冲区，异步刷新
- 无效化消息进入队列，延迟处理
- 不强制等待缓存状态转换完成

#### 步骤4：MESI协议正常执行
- 通过总线发送RFO请求获取缓存行独占权
- 其他核心异步处理无效化消息
- 不等待所有核心确认，允许延迟无效化

#### 步骤5：原子操作执行
- 在缓存锁定保护下执行读/写/RMW操作
- 保证单个操作的原子性
- 操作结果异步传播到其他核心

#### 步骤6：无内存屏障
- 不插入任何硬件内存屏障
- 允许后续操作与当前操作重排
- 不建立同步点

#### 步骤7：异步可见性传播
- 通过缓存一致性协议异步传播修改
- 不保证立即可见性
- 不同核心可能在不同时间看到修改

#### 步骤8：快速释放控制权
- 立即释放缓存行锁定
- 不等待全局同步
- 允许其他操作并发执行

